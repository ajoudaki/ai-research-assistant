@article{hochreiter1991untersuchungen,
  title={Untersuchungen zu dynamischen neuronalen Netzen},
  author={Hochreiter, Sepp},
  journal={Diploma thesis, Institut f{\"u}r Informatik, Lehrstuhl Prof. Brauer, Technische Universit{\"a}t M{\"u}nchen},
  year={1991}
}

@article{bengio1994learning,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994},
  publisher={IEEE}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013},
  organization={PMLR}
}

@article{hochreiter1998vanishing,
  title={The vanishing gradient problem during learning recurrent neural nets and problem solutions},
  author={Hochreiter, Sepp},
  journal={International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  volume={6},
  number={02},
  pages={107--116},
  year={1998},
  publisher={World Scientific}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}


@article{bengio2007scaling,
  title={Scaling learning algorithms towards AI},
  author={Bengio, Yoshua and LeCun, Yann},
  journal={Large-scale kernel machines},
  volume={34},
  number={5},
  pages={1--41},
  year={2007},
  publisher={MIT Press}
}



@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{castelvecchi2016can,
  title={Can we open the black box of AI?},
  author={Castelvecchi, Davide},
  journal={Nature News},
  volume={538},
  number={7623},
  pages={20},
  year={2016}
}


@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{bengio2009learning,
  title={Learning deep architectures for AI},
  author={Bengio, Yoshua},
  journal={Foundations and trends in Machine Learning},
  volume={2},
  number={1},
  pages={1--127},
  year={2009},
  publisher={Now Publishers Inc}
}

@article{saxe2013exact,
  title={Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
  author={Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
  journal={arXiv preprint arXiv:1312.6120},
  year={2013}
}


@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  journal={Icml},
  year={2010}
}

@inproceedings{pennington2017resurrecting,
  title={Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice},
  author={Pennington, Jeffrey and Schoenholz, Samuel and Ganguli, Surya},
  booktitle={Advances in neural information processing systems},
  pages={4785--4795},
  year={2017}
}

@article{klambauer2017self,
  title={Self-normalizing neural networks},
  author={Klambauer, G{\"u}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{frankle2018lottery,
  title={The lottery ticket hypothesis: Finding sparse, trainable neural networks},
  author={Frankle, Jonathan and Carbin, Michael},
  journal={arXiv preprint arXiv:1803.03635},
  year={2018}
}

@inproceedings{pennington2018emergence,
  title={The emergence of spectral universality in deep networks},
  author={Pennington, Jeffrey and Schoenholz, Samuel S and Ganguli, Surya},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1924--1932},
  year={2018},
  organization={PMLR}
}

@article{xiao2018dynamical,
  title={Dynamical isometry and a mean field theory of CNNs: How to train 10,000-layer vanilla convolutional neural networks},
  author={Xiao, Lechao and Bahri, Yasaman and Sohl-Dickstein, Jascha and Schoenholz, Samuel S and Pennington, Jeffrey},
  journal={arXiv preprint arXiv:1806.05393},
  year={2018}
}

@inproceedings{dong2021attention,
  title={Attention is not all you need: pure attention loses rank doubly exponentially with depth},
  author={Dong, Yihe and Cordonnier, Jean-Baptiste and Loukas, Andreas},
  booktitle={International Conference on Machine Learning},
  pages={2793--2803},
  year={2021},
  organization={PMLR}
}


@article{zhang2019fixup,
  title={Fixup initialization: Residual learning without normalization},
  author={Zhang, Hongyi and Dauphin, Yann N and Ma, Tengyu},
  journal={arXiv preprint arXiv:1901.09321},
  year={2019}
}

@article{daneshmand2020batch,
  title={Batch normalization orthogonalizes representations in deep random networks},
  author={Daneshmand, Hadi and Kohler, Jonas and Lucchi, Aurelien and Hofmann, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13968--13980},
  year={2020}
}

@article{santurkar2018does,
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{luo2019towards,
  title={Towards understanding regularization in batch normalization},
  author={Luo, Ping and Wang, Xinjiang and Shao, Wenqi and Peng, Zhanglin},
  journal={arXiv preprint arXiv:1809.00846},
  year={2019}
}

@article{poole2016exponential,
  title={Exponential expressivity in deep neural networks through transient chaos},
  author={Poole, Ben and Lahiri, Subhaneil and Raghu, Maithra and Sohl-Dickstein, Jascha and Ganguli, Surya},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{schoenholz2017deep,
  title={Deep information propagation},
  author={Schoenholz, Samuel S and Gilmer, Justin and Ganguli, Surya and Sohl-Dickstein, Jascha},
  journal={arXiv preprint arXiv:1611.01232},
  year={2017}
}

@article{hanin2019finite,
  title={Finite depth and width corrections to the neural tangent kernel},
  author={Hanin, Boris and Nica, Mihai},
  journal={arXiv preprint arXiv:1909.05989},
  year={2019}
}

@article{lu2020mean,
  title={The mean field limit of the generalized Langevin equation},
  author={Lu, Jianfeng and Lu, Yulong and Zhang, Zhongyang},
  journal={arXiv preprint arXiv:2004.03188},
  year={2020}
}

@inproceedings{yang2017mean,
  title={A mean field theory of batch normalization},
  author={Yang, Greg and Pennington, Jeffrey and Rao, Vinay and Sohl-Dickstein, Jascha and Schoenholz, Samuel S},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{yang2019scaling,
  title={Scaling limits of wide neural networks with weight sharing: Gaussian process behavior, gradient independence, and neural tangent kernel derivation},
  author={Yang, Greg},
  journal={arXiv preprint arXiv:1902.04760},
  year={2019}
}

@article{chen2018dynamical,
  title={Dynamical isometry and a mean field theory of RNNs: Gating enables signal propagation in recurrent neural networks},
  author={Chen, Minmin and Pennington, Jeffrey and Schoenholz, Samuel S},
  journal={arXiv preprint arXiv:1806.05394},
  year={2018}
}

@article{zhang2019root,
  title={Root mean square layer normalization},
  author={Zhang, Biao and Sennrich, Rico},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@article{srivastava2015training,
  title={Training very deep networks},
  author={Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1507.06228},
  year={2015}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={Advances in neural information processing systems},
  pages={3320--3328},
  year={2014}
}

@article{xu2018powerful,
  title={How powerful are graph neural networks?},
  author={Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:1810.00826},
  year={2018}
}

@article{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
  journal={arXiv preprint arXiv:1806.07366},
  year={2018}
}

@article{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  journal={Proceedings of the 26th International Conference on Machine Learning},
  pages={41--48},
  year={2009}
}

@inproceedings{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  booktitle={International Conference on Learning Representations},
  year={2015}
}