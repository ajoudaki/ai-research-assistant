{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "12da9ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhanced paragraph:\n",
      "\\chapter{Introduction}\n",
      "\n",
      "% \\subsection{The Rise and Challenges of Deep Neural Networks}\n",
      "Deep neural networks have revolutionized the field of artificial intelligence, achieving unprecedented performance in a wide range of tasks, from image recognition to natural language processing \\cite{zhang2019root, krizhevsky2012imagenet}. Despite their remarkable success, these models often remain enigmatic, functioning as ``black boxes'' that transform inputs into outputs through a complex series of non-linear operations. This opacity poses significant challenges for researchers and practitioners, as it hinders our ability to fully understand and optimize these powerful systems \\cite{castelvecchi2016can}.\n",
      "\n",
      "At the heart of the deep learning paradigm lies the concept of signal propagationâ€”the journey of information as it flows through the layers of a neural network during both forward and backward passes. Understanding this process is crucial for several reasons. It provides insights into how neural networks process and transform information, potentially illuminating the principles underlying their decision-making processes \\cite{schoenholz2017deep, zhang2019fixup}. A deeper understanding of signal propagation can guide the design of more efficient and effective network architectures. It informs the development of better optimization algorithms and training procedures \\cite{kingma2014adam, ioffe2015batch}. Finally, it contributes to the broader goal of making neural networks more principled and efficient \\cite{bengio2009learning, bengio2007scaling}.\n",
      "\n",
      "Reference analysis:\n",
      "{\n",
      "  \"paragraph\": \"\\\\chapter{Introduction}\\n\\n% \\\\subsection{The Rise and Challenges of Deep Neural Networks}\\nDeep neural networks have revolutionized the field of artificial intelligence, achieving unprecedented performance in a wide range of tasks, from image recognition to natural language processing \\\\cite{zhang2019root_uid=ef66, krizhevsky2012imagenet_uid=01dd}. Despite their remarkable success, these models often remain enigmatic, functioning as ``black boxes'' that transform inputs into outputs through a complex series of non-linear operations. This opacity poses significant challenges for researchers and practitioners, as it hinders our ability to fully understand and optimize these powerful systems \\\\cite{castelvecchi2016can_uid=5e84}.\\n\\nAt the heart of the deep learning paradigm lies the concept of signal propagation\\u2014the journey of information as it flows through the layers of a neural network during both forward and backward passes. Understanding this process is crucial for several reasons. It provides insights into how neural networks process and transform information, potentially illuminating the principles underlying their decision-making processes \\\\cite{schoenholz2017deep_uid=8305, zhang2019fixup_uid=2e78}. A deeper understanding of signal propagation can guide the design of more efficient and effective network architectures. It informs the development of better optimization algorithms and training procedures \\\\cite{kingma2014adam_uid=793d, ioffe2015batch_uid=87a7}. Finally, it contributes to the broader goal of making neural networks more principled and efficient \\\\cite{bengio2009learning_uid=f530, bengio2007scaling_uid=4ba8}.\",\n",
      "  \"explanations\": [\n",
      "    {\n",
      "      \"citation_id\": \"zhang2019root\",\n",
      "      \"uid\": \"ef66\",\n",
      "      \"score\": \"70%\",\n",
      "      \"explanation\": \"This citation is relevant to the context of optimization in deep neural networks due to its focus on layer normalization. However, the direct relevance to the general statement about performance in various tasks may not be very strong.\"\n",
      "    },\n",
      "    {\n",
      "      \"citation_id\": \"krizhevsky2012imagenet\",\n",
      "      \"uid\": \"01dd\",\n",
      "      \"score\": \"95%\",\n",
      "      \"explanation\": \"This is a highly relevant citation for the claim that deep neural networks have revolutionized image recognition. The paper is a landmark in the field of deep learning and provides solid evidence for the statement.\"\n",
      "    },\n",
      "    {\n",
      "      \"citation_id\": \"castelvecchi2016can\",\n",
      "      \"uid\": \"5e84\",\n",
      "      \"score\": \"85%\",\n",
      "      \"explanation\": \"This citation is quite relevant as it discusses the challenges of understanding 'black box' AI models, aligning well with the context about the opacity of deep neural networks. The source, however, is more of a news article rather than a peer-reviewed scientific paper, which slightly affects its reliability.\"\n",
      "    },\n",
      "    {\n",
      "      \"citation_id\": \"schoenholz2017deep\",\n",
      "      \"uid\": \"8305\",\n",
      "      \"score\": \"90%\",\n",
      "      \"explanation\": \"This citation is highly relevant to the discussion on signal propagation in neural networks. The paper delves deeply into the principles of deep information propagation, providing substantial support to the context.\"\n",
      "    },\n",
      "    {\n",
      "      \"citation_id\": \"zhang2019fixup\",\n",
      "      \"uid\": \"2e78\",\n",
      "      \"score\": \"85%\",\n",
      "      \"explanation\": \"This citation is relevant because it discusses techniques like Fixup initialization that relate to optimization and efficiency in neural networks. While not directly on signal propagation, it contributes significant related insights.\"\n",
      "    },\n",
      "    {\n",
      "      \"citation_id\": \"kingma2014adam\",\n",
      "      \"uid\": \"793d\",\n",
      "      \"score\": \"95%\",\n",
      "      \"explanation\": \"This is an excellent citation for discussing optimization algorithms in the context of neural networks. The Adam optimization algorithm is widely acknowledged and used in training neural networks efficiently.\"\n",
      "    },\n",
      "    {\n",
      "      \"citation_id\": \"ioffe2015batch\",\n",
      "      \"uid\": \"87a7\",\n",
      "      \"score\": \"90%\",\n",
      "      \"explanation\": \"This is a strong citation for discussing techniques to improve training efficiency. Batch normalization has become a standard method in training deep neural networks, aligning well with the context provided.\"\n",
      "    },\n",
      "    {\n",
      "      \"citation_id\": \"bengio2009learning\",\n",
      "      \"uid\": \"f530\",\n",
      "      \"score\": \"80%\",\n",
      "      \"explanation\": \"This citation is relevant for its contributions to understanding deep learning architectures and their optimization. However, it might be considered somewhat general when it comes to the specific point about signal propagation.\"\n",
      "    },\n",
      "    {\n",
      "      \"citation_id\": \"bengio2007scaling\",\n",
      "      \"uid\": \"4ba8\",\n",
      "      \"score\": \"75%\",\n",
      "      \"explanation\": \"This citation is relevant for discussions on scaling learning algorithms and general optimization in AI. Although it provides good foundational knowledge, it might not be directly tied to the specific points in signal propagation discussed in the paragraph.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import requests\n",
    "from typing import List, Dict, Any\n",
    "import bibtexparser\n",
    "from bibtexparser.bwriter import BibTexWriter\n",
    "from bibtexparser.bibdatabase import BibDatabase\n",
    "from openai import OpenAI\n",
    "\n",
    "class SemanticScholarAPI:\n",
    "    BASE_URL = \"https://api.semanticscholar.org/graph/v1\"\n",
    "    DEFAULT_PAPER_FIELDS = \"paperId,title,abstract,year,citationCount,influentialCitationCount,authors,venue,publicationVenue,journal,url\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.headers = {\"x-api-key\": api_key}\n",
    "\n",
    "    def _make_request(self, endpoint: str, method: str = \"GET\", params: Dict[str, Any] = None, data: Dict[str, Any] = None) -> Dict[str, Any]:\n",
    "        url = f\"{self.BASE_URL}/{endpoint}\"\n",
    "        response = requests.request(method, url, headers=self.headers, params=params, json=data)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def fetch_paper_details(self, paper_id: str) -> Dict[str, Any]:\n",
    "        return self._make_request(f\"paper/{paper_id}\")\n",
    "\n",
    "    def fetch_paper_details_batch(self, paper_ids: List[str], fields: str = DEFAULT_PAPER_FIELDS) -> List[Dict[str, Any]]:\n",
    "        return self._make_request(\"paper/batch\", method=\"POST\", data={\"ids\": paper_ids, \"fields\": fields})\n",
    "\n",
    "    def search_papers(self, query: str, limit: int = 10) -> Dict[str, Any]:\n",
    "        return self._make_request(\"paper/search\", params={\"query\": query, \"limit\": limit, \"fields\": self.DEFAULT_PAPER_FIELDS})\n",
    "\n",
    "    def search_papers_batch(self, queries: List[str], limit: int = 10) -> List[Dict[str, Any]]:\n",
    "        data = {\"queries\": [{\"query\": q, \"limit\": limit} for q in queries], \"fields\": self.DEFAULT_PAPER_FIELDS}\n",
    "        return self._make_request(\"paper/search/batch\", method=\"POST\", data=data)\n",
    "\n",
    "    def fetch_paper_references(self, paper_id: str, limit: int = 10) -> Dict[str, Any]:\n",
    "        return self._make_request(f\"paper/{paper_id}/references\", params={\"fields\": \"paperId,title,year,authors\", \"limit\": limit})\n",
    "\n",
    "    def fetch_paper_references_batch(self, paper_ids: List[str], fields: str = \"paperId,title,year,authors\", limit: int = 10) -> Dict[str, Any]:\n",
    "        return self._make_request(\"paper/batch/references\", method=\"POST\", data={\"ids\": paper_ids, \"fields\": fields, \"limit\": limit})\n",
    "\n",
    "    def fetch_paper_citations(self, paper_id: str, limit: int = 10) -> Dict[str, Any]:\n",
    "        return self._make_request(f\"paper/{paper_id}/citations\", params={\"fields\": \"paperId,title,year,authors\", \"limit\": limit})\n",
    "\n",
    "    def fetch_paper_citations_batch(self, paper_ids: List[str], fields: str = \"paperId,title,year,authors\", limit: int = 10) -> Dict[str, Any]:\n",
    "        return self._make_request(\"paper/batch/citations\", method=\"POST\", data={\"ids\": paper_ids, \"fields\": fields, \"limit\": limit})\n",
    "\n",
    "class BibTexHandler:\n",
    "    @staticmethod\n",
    "    def convert_entries_to_bibtex(entries: List[Dict[str, Any]]) -> str:\n",
    "        db = BibDatabase()\n",
    "        db.entries = entries\n",
    "        writer = BibTexWriter()\n",
    "        return writer.write(db)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_bibtex_content(bibtex_content: str) -> List[Dict[str, Any]]:\n",
    "        parser = bibtexparser.bparser.BibTexParser(common_strings=True)\n",
    "        bib_database = bibtexparser.loads(bibtex_content, parser)\n",
    "        return bib_database.entries\n",
    "\n",
    "class LaTeXHandler:\n",
    "    @staticmethod\n",
    "    def replace_latex_citations_with_uids(latex_text: str) -> str:\n",
    "        def replace_citation(match):\n",
    "            command, optional, citations = match.groups()\n",
    "            optional = optional or ''\n",
    "            if not citations:\n",
    "                return f\"\\\\{command}{optional}{{}}\"\n",
    "            replaced_citations = [f\"{citation.strip()}_uid={str(uuid.uuid4())[:4]}\" for citation in citations.split(',')]\n",
    "            return f\"\\\\{command}{optional}{{{', '.join(replaced_citations)}}}\"\n",
    "\n",
    "        citation_pattern = r'\\\\(cite|citet|citep)(\\[.*?\\])?{(.*?)}'\n",
    "        return re.sub(citation_pattern, replace_citation, latex_text)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_latex_citations(latex_text: str) -> List[str]:\n",
    "        citation_pattern = r'\\\\(?:cite|citet|citep)(?:\\[.*?\\])?{(.*?)}'\n",
    "        matches = re.findall(citation_pattern, latex_text)\n",
    "        return [citation.strip() for match in matches for citation in match.split(',')]\n",
    "\n",
    "class GPTEnhancer:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.openai_client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def enhance_paragraph_with_references(self, paragraph: str, bibliography: str) -> str:\n",
    "        system_prompt = \"You are an AI assistant that enhances academic writing.\"\n",
    "        user_prompt = f\"\"\"\n",
    "        Given the following LaTeX paragraph and bibliography, add appropriate references from the bibliography.\n",
    "        You can either add references to existing \\\\cite, \\\\citep, or \\\\citet commands, or add new ones wherever needed.\n",
    "        Attention: Make sure not to remove any existing citations. \n",
    "        Only print the output. \n",
    "\n",
    "        ```latex\n",
    "        (tex with added references)\n",
    "        ```\n",
    "\n",
    "        Paragraph:\n",
    "        {paragraph}\n",
    "\n",
    "        Bibliography:\n",
    "        {bibliography}\n",
    "        \"\"\"\n",
    "\n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # Replace with the appropriate model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=3000,\n",
    "        )\n",
    "\n",
    "        enhanced_text = response.choices[0].message.content\n",
    "        latex_match = re.search(r'```latex\\s*([\\s\\S]*?)\\s*```', enhanced_text)\n",
    "        return latex_match.group(1) if latex_match else None\n",
    "\n",
    "    def analyze_references(self, paragraph_with_refs: str, parsed_bibliography: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        citations = LaTeXHandler.extract_latex_citations(paragraph_with_refs)\n",
    "        relevant_entries = [entry for entry in parsed_bibliography for ref in set(citations) if entry['ID'] == ref]\n",
    "        references_bibtex = BibTexHandler.convert_entries_to_bibtex(relevant_entries)\n",
    "        paragraph_with_uids = LaTeXHandler.replace_latex_citations_with_uids(paragraph_with_refs)\n",
    "\n",
    "        system_prompt = \"You are an AI assistant that enhances academic writing.\"\n",
    "        user_prompt = f\"\"\"\n",
    "        Given the following LaTeX and bibliography, add appropriate explanations for each unique key,\n",
    "        and explain if it is a good citation or not. Give a score of 0-100% in terms of being a good citation\n",
    "        Try to be extremely critical and judicious, and use a low score if a citation is not clearly relevant to the context or not.\n",
    "\n",
    "        Output must be in a JSON format, as an array of items:\n",
    "\n",
    "        ```json\n",
    "        [{{\n",
    "            \"citation_id\": \"(the BibTeX ID)\",\n",
    "            \"uid\": \"(uid)\",\n",
    "            \"score\": \"(score)\",\n",
    "            \"explanation\": \"(Explaining if this is a good citation, and if yes, why)\"\n",
    "        }}]\n",
    "        ```\n",
    "\n",
    "        Paragraph: \n",
    "        {paragraph_with_uids}\n",
    "\n",
    "        Bibliography:\n",
    "        {references_bibtex}\n",
    "        \"\"\"\n",
    "\n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # Replace with the appropriate model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=2000,\n",
    "        )\n",
    "\n",
    "        analysis_text = response.choices[0].message.content\n",
    "        json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', analysis_text)\n",
    "        explanations = json.loads(json_match.group(1)) if json_match else []\n",
    "        return {\n",
    "            'paragraph': paragraph_with_uids, \n",
    "            'explanations': explanations,\n",
    "        }\n",
    "\n",
    "semantic_scholar_api = SemanticScholarAPI(os.getenv('S2_API_KEY'))\n",
    "gpt_enhancer = GPTEnhancer(os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "with open('sample2.tex', 'r') as f:\n",
    "    paragraph = f.read()\n",
    "\n",
    "with open('sample.bib', 'r') as f:\n",
    "    bibliography = f.read()\n",
    "\n",
    "parsed_bibliography = BibTexHandler.parse_bibtex_content(bibliography)\n",
    "\n",
    "enhanced_paragraph = gpt_enhancer.enhance_paragraph_with_references(paragraph, bibliography)\n",
    "print('\\nEnhanced paragraph:')\n",
    "print(enhanced_paragraph)\n",
    "\n",
    "reference_analysis = gpt_enhancer.analyze_references(enhanced_paragraph, parsed_bibliography)\n",
    "print('\\nReference analysis:')\n",
    "print(json.dumps(reference_analysis, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd0840-7aae-4c42-9202-285672357d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bdbb8-d90e-47d8-9b61-07d1fa94317e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8266a0bd-35be-4dca-be0d-1db8863376fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_search_batch(\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
