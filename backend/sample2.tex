% \subsection{The Rise and Challenges of Deep Neural Networks}
Deep neural networks have revolutionized the field of artificial intelligence, achieving unprecedented performance in a wide range of tasks, from image recognition to natural language processing \cite{zhang2019root}. Despite their remarkable success, these models often remain enigmatic, functioning as ``black boxes'' that transform inputs into outputs through a complex series of non-linear operations. This opacity poses significant challenges for researchers and practitioners, as it hinders our ability to fully understand and optimize these powerful systems.

At the heart of the deep learning paradigm lies the concept of signal propagationâ€”the journey of information as it flows through the layers of a neural network during both forward and backward passes. Understanding this process is crucial for several reasons. It provides insights into how neural networks process and transform information, potentially illuminating the principles underlying their decision-making processes. A deeper understanding of signal propagation can guide the design of more efficient and effective network architectures. It informs the development of better optimization algorithms and training procedures. Finally, it contributes to the broader goal of making neural networks more principled and efficient.

The importance of signal propagation becomes particularly evident when considering the challenges associated with training very deep neural networks. As networks grow in depth, they gain the potential for increased expressivity and the ability to learn more complex representations \cite{bengio2009learning}. However, this increased depth also introduces significant obstacles to effective training, many of which are directly related to how signals propagate through the network.